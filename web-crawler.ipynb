{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T13:46:21.575337Z","iopub.execute_input":"2025-12-07T13:46:21.575574Z","iopub.status.idle":"2025-12-07T13:46:24.227461Z","shell.execute_reply.started":"2025-12-07T13:46:21.575553Z","shell.execute_reply":"2025-12-07T13:46:24.226239Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin, urlparse\nimport time\n\ndef is_valid_url(url):\n    \"\"\"Checks if the URL has a scheme (http/https) and netloc.\"\"\"\n    parsed = urlparse(url)\n    return bool(parsed.netloc) and bool(parsed.scheme)\n\ndef crawl_websites(urls_list):\n    \"\"\"\n    Iterates through a list of URLs and crawls them.\n    \"\"\"\n    # Set a User-Agent to act like a real browser\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n\n    for url in urls_list:\n        print(f\"\\n{'='*60}\")\n        print(f\"[*] Starting Crawl: {url}\")\n        print(f\"{'='*60}\")\n\n        try:\n            # 1. Fetch the content\n            response = requests.get(url, headers=headers, timeout=10)\n            \n            if response.status_code != 200:\n                print(f\"[!] Failed to retrieve {url} (Status: {response.status_code})\")\n                continue\n\n            # 2. Parse the HTML\n            soup = BeautifulSoup(response.text, 'html.parser')\n            \n            # 3. Extract links\n            links = soup.find_all('a', href=True)\n            unique_links = set()\n\n            for link in links:\n                href = link['href']\n                # Convert relative paths (/about) to absolute (https://site.com/about)\n                full_url = urljoin(url, href)\n                \n                if is_valid_url(full_url):\n                    unique_links.add(full_url)\n\n            # 4. Output results\n            print(f\"[*] Success! Found {len(unique_links)} unique links:\\n\")\n            \n            # Print only the first 20 links to keep Jupyter clean (remove slice to see all)\n            for i, link in enumerate(list(unique_links)): \n                print(f\" {i+1}. {link}\")\n            \n            if len(unique_links) > 20:\n                print(f\"\\n... and {len(unique_links) - 18} more links.\")\n\n        except requests.exceptions.RequestException as e:\n            print(f\"[!] Error connecting to {url}: {e}\")\n        \n        # Be polite to servers\n        time.sleep(1)\n\n# ==========================================\n# INPUT: Define your websites here\n# ==========================================\nwebsites_to_crawl = [\n    \"https://www.buroojinstitute.org\",\n    \"https://azaan.com.pk/\"\n]\n\n# Run the crawler\ncrawl_websites(websites_to_crawl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T13:48:54.560021Z","iopub.execute_input":"2025-12-07T13:48:54.561233Z","iopub.status.idle":"2025-12-07T13:49:06.247026Z","shell.execute_reply.started":"2025-12-07T13:48:54.561195Z","shell.execute_reply":"2025-12-07T13:49:06.245535Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\n[*] Starting Crawl: https://www.buroojinstitute.org\n============================================================\n[*] Success! Found 37 unique links:\n\n 1. https://forms.gle/yfAT8vX1TRvSzbRs8\n 2. https://www.linkedin.com/company/burooj-institute/\n 3. https://buroojinstitute.org\n 4. https://www.buroojinstitute.org/about-us/\n 5. https://buroojinstitute.org/donation/\n 6. https://www.instagram.com/buroojinstituteofficial/\n 7. https://docs.google.com/forms/d/e/1FAIpQLSdI8-NaeQWK59JggCpm92g8AAagZFXq5sBBrSFcuueEeHByzw/closedform\n 8. https://forms.gle/LmidwGyk1E5gxM2s7\n 9. https://buroojinstitute.org/burooj-instructors/\n 10. https://buroojinstitute.org/basic-tajweed-course-female/\n 11. https://buroojinstitute.org/workshops/\n 12. https://www.buroojinstitute.org/upcoming-program/\n 13. https://forms.gle/6ZDXzjjqeeQ6fayg8\n 14. https://www.buroojinstitute.org/deen-foundations/\n 15. https://buroojinstitute.org/alim-alimah-winter-online-2025/\n 16. https://buroojinstitute.org/alim-alimah-winter-onsite-2025/\n 17. https://forms.gle/xjWVHgsnnL2yBCa28\n 18. https://buroojinstitute.org/\n 19. https://buroojinstitute.org/basic-tajweed-course-male/\n 20. https://buroojinstitute.org/at-tasees-winter-onsite-2025/\n 21. https://www.buroojinstitute.org/\n 22. https://www.buroojinstitute.org/privacy-policy/\n 23. https://www.buroojinstitute.org/course/hadith-foh-and-u/\n 24. https://www.facebook.com/buroojinstituteofficial\n 25. https://www.buroojinstitute.org/online-arabic-language-course/\n 26. https://www.buroojinstitute.org/workshops/\n 27. https://www.buroojinstitute.org/campus/\n 28. https://www.buroojinstitute.org/burooj-instructors/\n 29. https://www.buroojinstitute.org\n 30. https://www.buroojinstitute.org/contact-us/\n 31. https://www.buroojinstitute.org/broadcast-live/\n 32. https://www.youtube.com/@BuroojInstituteofficial\n 33. https://www.buroojinstitute.org/course/q-s-y/\n 34. https://www.buroojinstitute.org/course/fot-hadith/\n 35. https://buroojinstitute.org/at-tasees-winter-online-2025/\n 36. https://www.buroojinstitute.org/course/ag-bar-201/\n 37. https://forms.gle/qVbHpcBc514ddnF36\n\n... and 19 more links.\n\n============================================================\n[*] Starting Crawl: https://azaan.com.pk/\n============================================================\n[*] Success! Found 19 unique links:\n\n 1. https://azaan.com.pk/instructors/\n 2. https://www.youtube.com/@AzaanInstitutePakistan\n 3. https://azaan.com.pk/onsite-courses/\n 4. https://azaan.com.pk/my-account\n 5. http://my%20account\n 6. https://azaan.com.pk/contact-us-new/\n 7. https://online.azaan.com.pk/my-account/\n 8. https://azaan.com.pk/faqs/\n 9. https://www.instagram.com/azaaninstitute/?hl=en\n 10. https://register.azaan.com.pk/product/advice-of-the-wise-islamabad/\n 11. https://www.youtube.com/c/AzaanInstitutePakistan\n 12. https://azaan.com.pk/faqs//\n 13. https://azaan.com.pk/about-us/\n 14. https://www.facebook.com/AzaanKarachi/\n 15. https://www.dabbssolutions.com/\n 16. https://register.azaan.com.pk/product/leadership-beyond-power-karachi/\n 17. https://azaan.com.pk\n 18. https://azaan.com.pk/online-courses/\n 19. https://azaan.com.pk/\n","output_type":"stream"}],"execution_count":4}]}